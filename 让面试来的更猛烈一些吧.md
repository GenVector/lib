# 让面试来的更猛烈一些吧

其实面试主要还是靠缘分，有时候你准备充分，但是遇到剑走偏锋，也就挂了，有时候表现完美，忽然新单位的人头就没了，也拿不到offer。所以有时候也要有个好心态，佛一点比较好。其实最重要的事情永远是做好自己，修炼内功，如果自己的水平到了一定的层次，即使这一家爆冷了又如何，总会遇到合适的。下面是从知乎里摘取的一些面试题，且听说细说。

### Java的线程池说一下，各个参数的作用，如何进行的?

线程池是为了避免频繁创建线程的开支而创建的一个可以反复使用的线程集合。很多情况下图方便我们都使用`Executors#xxxPool()`这个工厂来创建线程池，但这样创建出来的线程池其实有很多默认参数，潜藏着OOM的问题，即：在任务不断提交，而线程来不及处理时，任务就会积压在线程池的任务队列里面，直至爆内存；或者说，在任务不断提交，但没有限制最大线程数量时，不断创建新的线程，也会先搞垮CPU，最终搞垮内存。因此，在阿里的Java规范中，不允许使用`Executors`来建立线程池，而必须手动建立。

手动建立的线程池是`ThreadPoolExecutor`，主要有这么几个参数：线程池核心线程数量；线程池最大线程数量；是否在创建时就建立核心线程；线程池回收线程的超期时间；在任务堆积时线程池使用的任务队列；线程池在任务队列满、线程池数量也达到最大时的策略；还可以传入一个线程工厂，主要用于给线程命名（减轻debug负担），调整线程优先级等，比如我深度怀疑在Spring Security中，认证信息可以跨线程传播，就可能是使用了线程工厂。

在默认的FixThreadPool中，核心数量等于最大线程数量，按需创建线程，不会回收线程，使用了无界队列，线程池数量达到最大后，使用默认策略，也就是抛一个拒绝执行的异常，但实际上因为它使用了无界任务队列，根本不可能抛异常，只会爆内存。

拒绝策略包括抛异常、在生产者线程直接执行任务（拿出任务来直接在生产者线程调用其run()方法），直接丢弃任务，或者丢弃最早的任务。

队列包括ArrayBlockingQueue，就是有界队列；LinkedBlockingQueue，就是无界队列；SynchronousQueue，hand to hand队列，就是只有当有消费者的时候，任务才能提交成功，不然会阻塞，用于`Executors#newCachedThreadPool()`，这样他会一直新建线程；还有双端队列，用于任务窃取线程池，主要是`Fork/Join`框架在用。

在默认情况下，一个线程池达到核心线程数量以后再来任务，会把任务放到队列里，不会新建线程，直到队列满了才新建线程，直到最大线程数量，然后再来任务，就会执行拒绝策略。

等到非核心线程空置的时间达到超时时间时（这里很巧妙地让所有线程都在工作队列上等待，等到超时时间后退出，这样的话他就可以判断如果此时线程池的线程数量超出了核心线程数量，就释放线程资源），这些线程就会被回收。但是在默认情况下，核心线程不会被回收，需要配置。

线程池在没有任务提交、所有线程都回收后，才会被垃圾收集器光顾，因此如果想要垃圾收集器回收线程池，就需要设立合理的超时时间、并且允许回收核心线程。但是线程池作为一个全局资源，一般也不太需要说垃圾收集器一定回收它。

### 同步与异步区别？

同步是指被调用者在返回时，被调用者的工作就已经全部作为，调用者就可以拿到返回值。

异步是指被调用者在返回时，被调用者只是明确自己接收了任务，任务不一定执行完毕，调用者不能立刻得到其返回值，需要使用其他方式拿到返回值，比如说一个Future，等待被调用者通知或者直接提供给被调用者一个回调函数，让被调用者在任务完成后执行。

其核心区别在于，被调用者返回时其工作是否完成，调用者是否能够拿到其返回值。

### HashMap的实现原理，HashMap是如何解决hash冲突的问题？

JDK1.7以前，是Hash数组+链表的形式；

JDK1.8以后，改为Hash数组+（链表 或者 红黑树）的形式。

### 乐观锁，悲观锁?

乐观锁是指，认为一般情况下不会发生竞争，因此总是去尝试直接修改值，如果修改成功那就OK，修改不成功就获取最新值再来一遍。

悲观锁是指，认为一般情况下都会发生竞争，因此总是在资源上加上排它锁，在自己访问时阻止其他任务访问资源。

现在一些追求高性能的环境下，乐观锁非常常见，比如说java的线程安全对象：LongAdder，AtomicLong；或者JDK1.8下的ConcurrentHashMap；再或者数据库的version；再者`Synchorized`关键字的具体实现，等等。这些思想的核心是CAS，就是Compare And Swap，比如说我们多线程对一个数字加5，这时候两个线程都读到这个数字原来是10，传统方法可能是加锁，但是加锁开销很大，而CAS假设没有其他线程操作这个数字，于是它在一个原子操作里，比较这个数字是不是10，如果是，就把他加5，如果不是，就获得最新值，再重复以上操作，直到设置成功。因为比较和设置是一个原子操作（CPU支持），所以是线程安全的。

而悲观锁呢，就是不管有没有其他线程和我竞争，我一上来就先锁住这个资源，加锁和释放锁都需要操作系统支持，是一个比较重的操作（虽然后来JVM给了一些优化措施，比如说自旋锁、偏向锁、轻量锁等，但是只要没有竞争，这个加锁操作的消耗就是浪费），所以性能一般而言是差一点。

但是凡事不绝对，在竞争非常激烈的情况下，乐观锁会只有一个线程设置成功，其他线程不断重试，反复如此，反而会降低效率，而此时加锁排队，其他线程都阻塞，反而性能好一点。比如如果仔细观察LongAdder的设计，就会发现他为了避免乐观锁在竞争激烈的情况下反复失败，把一个加数分成了很多个，其加和代表当前的值，把竞争分散了。

一个手写的乐观锁的SQL如下：

```sql
update table t set t.version=t.version+1 and t.realValue=value 
			 where t.version = oldVersion and other requirement
```

### IO和NIO的区别，以及NIO的原理

这个问题其实多少有些问题，IO和NIO不是一个层面的东西，就像你问：马和白马的区别，比较诡异。合适的问法是：BIO和NIO的区别，或者还有AIO。

BIO是JDK1.4以前Java唯一可选的IO模式，其全名是`Blocking-IO`，意思是所有的IO请求都会阻塞当前线程的工作，这个阻塞的时间内，其实操作系统在做很多事情，比如说，等待请求建立、等待数据传输、数据传输后从内核空间复制到用户空间，这些过程一直是阻塞的。阻塞时线程会失去CPU的使用权，为了避免这种情况，我们一般会启动多线程去干这个事情。但是多线程也有多线程的问题，比如建立太多线程会内存溢出、线程切换的成本会很高等。而且，我们真的需要线程在IO的所有阶段都等待吗？包括等待请求建立，等待用户传递数据的阶段……假如网络抖动，那我简直就是干等啊。

哪里有问题，哪里就有大神。于是JDK1.4以后推出了新的IO模型，即`NIO(Non-Blocking IO)`，在等待连接建立、等待用户传递数据的过程中，他都不会去阻塞。相反，他用一个线程启动了一个轮询器(Selector)去监听多个连接（Channel），在这些channel建立连接时，或者等待数据传输过来时，这个轮询器就非阻塞地在多个连接直接轮询，等到有连接数据准备好可以复制了，这时候可以用多线程再去处理IO的结果。这就省掉了等待连接、等待数据传输的时间，线程可以做更多有意义的工作了。

和面向流的BIO不用，NIO会用一个Buffer来拷贝数据，这个Buffer可以读也可以写，是可以翻转的。但BIO还有个小问题，就是其实数据准备以后，我们还是需要线程阻塞地去复制一下的，如果这一步复制都不用了，直接等复制完了通知我处理多好，甚至，我给个回调函数，等复制完了直接执行吼不吼啊？

那当然是坠吼的，所以JDK1.7推出了的IO类，官方称为NIO2.0，但因为其异步特性，经常被称为AIO，他允许我们给给一个回调函数，等内核复制完数据后直接调用该函数。主线程可以交完任务就不管了，而回调函数可以维护线程池去做，挺棒的。

但是如果真的用过NIO和AIO，就会发现这些低层的API是真难用啊，说破天，这些东西还是主要面向字节的，于是无论是Http连接数据，还是Ftp连接数据，都得你自己手动去解析，连一个连接传过来的多段数据，你都要自己去拼接、定界。苦不堪言，所以大家其实都用在这之上封装好的框架，比如大名鼎鼎的Netty。

### 反射的作用是什么？

这个问的可能不是镜面反射和漫反射的那个反射。

反射是指通过Java的Class对象，直接获得关于一个类的内部构造，包括其字段、方法、构造函数等。反射在很多地方都用到了，比如说，Spring中就大量使用了反射进行应用上下文和Bean的构建、动态代理的实现等；JPA框架用反射来完成数据库字段到类字段的映射，Json转换类库使用反射来完成字符串到类字段的映射等。

反射会有一定的性能问题，为什么呢？

> Because reflection involves types that are dynamically resolved, certain Java virtual machine optimizations can not be performed. Consequently, reflective operations have slower performance than their non-reflective counterparts, and should be avoided in sections of code which are called frequently in performance-sensitive applications.
>
> 翻译：因为反射方法使用的类型都是动态装载的，某些虚拟机的优化不能执行。因此反射操作与同样功能的非反射代码相比执行效率要低，所以应该在性能敏感的应用中避免频繁使用反射。

那么反射到底慢在哪里，以及反射到底慢多少？可以参考：[Java反射到底慢在哪？](https://www.jianshu.com/p/4e2b49fa8ba1)

### 为什么要使用线程池？

如果是问为什么使用多线程，那就是为了充分发挥多CPU的优势，以及避免应用在阻塞时失去CPU的使用权；

那用线程池呢？就只有一个目的，降低建立线程的消耗。

### 说说几种常见的线程池及使用场景

上面提到了一部分。这个问题的问题本身也不是很清晰，如果问的是用`Executors`建立出来的线程池有多少种，那就是`newFixedThreadPool`， `newCachedThreadPool`， `newSingleThreadExecutor`， `newSingleThreadScheduledExecutor`，`newWorkStealingPool`这几种。但要细究起来，这些建立出来的线程池可以分为以下几个类：

实际上线程池有`ThreadPoolExecutor`，`ScheduledThreadPoolExecutor`和`WorkStealPool`。

前两个没什么好介绍的，最后一个主要用于Fork/Join框架，他的主要特点是，提交给线程池的任务最开始是一个一整块的大任务，然后这些任务会把自己细分再放到工作队列里，直到任务切分到合适的大小才会进行计算，分任务完成后，最后再将结果合并在一起，这个场景最容易想到的就是归并排序了。为什么叫`WorkStealPool`呢，是因为这个线程池使用的工作队列是双端队列，一个线程在完成自己的工作后，会从其他线程的任务队列里取出一些工作来做。所以叫`任务窃取`（主动干活怎么能叫偷呢……）

所以使用场景也没什么好介绍的了。

### 怎么理解无界队列和有界队列？

就是容量是不是有上限呗，无界队列感觉还是用链表好实现一些，但有界队列就可以用环状数组了，就是实现的时候要格外小心一点。

### 你怎么理解http协议

Http协议是OSI模型中的应用层协议，他是一个无状态的协议，定义了一些操作方法，比如Get、Post、Delete、Patch、Put、HEAD、OPTIONS、TRACE、CONNECT等，一个Http报文包括：

+ 开始行

  请求报文的开始行由方法、[空格]、URL、[空格]、HTTP版本构成。

  响应报文的开始行由HTTP 版本、[空格]、状态码构成。状态码主要包括：

  + 1xx：表示服务器收到请求，正在处理；
  + 2xx：处理正常，200一切正常
  + 3xx：表示重定向，302重定向
  + 4xx：客户端错误，403鉴权失败，404资源未发现，
  + 5xx：服务器错误，500服务器内部错误，503服务不可用。

+ 首部行

+ 实体主体（Entity Body）

### OSI七层模型包括哪七层？

应用层、会话层、表示层、传输层、网络层、链路层、物理层。

### 说说http协议的工作流程

这不是经典的输入URL敲回车后发生了什么的简化版？

感觉Http协议的工作流程没什么好说的啊，不知道问啥呢。如果不提DNS解析和TCP传输，只说Http，无非就是Http报文封装，然后让TCP发送给服务端，服务端收到后解析请求的具体含义，然后返回一个Http报文，客户端再解析，展示，如此而已。

### http get和post有什么区别

首先其语义就是有区别的，Get是从服务器获得一个资源，而Post是向服务器提交一个资源。

从具体的是线上来看，Get请求不能携带`Entity Body`，只能将参数放在URL里面，但Post可以把参数放在`Entity Body`里，因此理论上比Get更适合传输一些敏感点数据，以及体积更大的数据。（但要考虑到被抓包的可能，只要不是加密的，就安全不到哪里去）

因为语义上的区别，衍生出很多其他区别。

Get是幂等的，多次执行的结果应该一致，而Post则不一定，比如你可以多次get一个商品的详情，但要是多次Post一个订单，可能会买10个，哈哈。

### 你怎么理解cookie和session，有哪些不同点

这根本就是两个完全不同层面的概念。

session的意思是会话，这个概念广泛存在于服务器与客户端之间的通信过程中。所谓会话，就是客户端与服务器之间的一次完整的通信过程。比如Http有session的概念，其实数据库通信也有session的概念。

Http通信为什么会有会话这个概念？是因为Http协议是无状态的，也就是说对于服务器来说，一次性求和一次请求之间没有联系，那么一些场景下应用就很受限。比如说淘宝购物车，一次请求和一次请求之间没有关系的话，怎么知道选的一个物品添加到谁的购物车去了。

因此有了session的概念，就是通过某种方式来维持服务器和客户端之间的多次通信，使得在这些通信之间，服务器和客户端之间维持着一些状态，从而允许服务器识别客户端的身份。可想而知，session这个概念可以有很多种实现方式，而使用cookie实现就是其中一种实现。

cookie是由网景公司提出来的技术，就是在Http报文的Header区添加与Session相关的Header，服务器端在发往客户端的报文中带一个`set-cookie`的header，浏览器就会在返回的报文中加一个`cookie`的header，而且在之后与服务器的通信中，只要cookie没有过期，就会一直发送这个cookie，服务器以此认证客户端的身份。

所以session是一种旨在允许服务器和客户端在多次通信中维持一些状态的概念，cookie是这个概念的一种实现。

### 什么是web缓存？有什么优点？

唔，这就像有人问，缓存是什么。缓存是什么呢？是一种加速资源访问速度的技术，其核心要么是将资源放在速度更快的存储器里（redis的内存缓存），或者放在距离用户更近的节点上（缓存服务器CDN）等，以加速客户访问资源的速度。

web缓存主要是指浏览器缓存和缓存服务器。

优点一是降低服务器的压力，一些比较大又耗资源的服务可以直接放在缓存里。二是提高访问速度，因为往往缓存距离用户更近一些。

缓存最主要的是解决和最新资源的一致性问题，以及解决一些语义问题。一些不规范的Restful接口写法，如果用200返回错误，就有可能被缓存导致错误。

一个Http报文中，可以有相关的字段表明自己是否应当被缓存、最多缓存多长时间等等。

### 什么是https，说说https的工作原理？

[SSL/TLS协议运行机制的概述](https://www.ruanyifeng.com/blog/2014/02/ssl_tls.html)

Https是指Http Over TLS，意思是在加密的Http报文协议。它主要解决Http协议使用明文传输数据带来的几个问题：窃听风险、篡改风险和身份冒充风险。其解决的问题主要包括：

1. 对报文进行加密传输，防止窃听。
2. 报文的完整性校验。防止篡改。
3. 通信双方的身份验证，既包括服务端认证客户端身份，以及客户端认证服务端身份。

工作原理很简单，就是把Http报文内容经过TLS加密之后再传输。最早用的加密协议是SSL，即Secure Sockets Layer，安全套接字层，经过了几个版本迭代以后，现在都已经被认为不安全，所以当前比较广泛使用的是TLS1.3，Transport Layer Security，即传输层安全协议。其具体实现相当复杂。

TLS协议最重要概念是其握手阶段，这个阶段所有的通信都是明文的，这主要包含四个步骤。

1. 客户端发出请求（ClientHello）

   + 支持的协议版本，比如TLS 1.0版。

   + 一个客户端生成的随机数，稍后用于生成"对话密钥"。

   + 支持的加密方法，比如RSA公钥加密。

   + 支持的压缩方法。

2. 服务器回应（SeverHello）

   + 确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。一般服务器会对加密方法的强度有最低要求，防止被中间人攻击时被迫选择加密强度不够的加密算法。

   + 一个服务器生成的随机数，稍后用于生成"对话密钥"。

   +  确认使用的加密方法，比如RSA公钥加密。

   + 服务器证书。

   有时候，服务器会要求验证客户端的身份，这时候可能会要求客户端提供证书。

3. 客户端回应

   + 一个随机数。该随机数用服务器公钥加密，防止被窃听。

   + 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。

   + 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。在一定程度上是报文完整性的一个校验。
   + 如果前一步，服务器要求客户端证书，客户端会在这一步发送证书及相关信息。

4. 服务器的最后回应

   + 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。

   + 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验。

在这里，为了防止服务器身份假冒，即保证服务器的证书可验证，使用了证书的概念，由一些根证书机构签发一些证书，把服务器的域名等信息经过完整性校验后放在证书里面，只要证书的签发机构可信（由浏览器保证），那么这个证书就是可信的。

### 什么是Http代理服务器，有什么用

所谓代理，就是用户和服务器之间的信息中转站。使用代理一般来说是为了访问难以直接访问的资源，还可以包括安全性校验、内容过滤、缓存、访问控制、流量分发等功能。

主要分为正向代理和反向代理。

正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。

反向代理正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置。客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好似他自己一样，一次客户端并不会感知到反向代理后面的服务，也因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了。nginx就是非常著名的反向代理服务器。

### 什么是虚拟主机及实现原理

虚拟主机，也叫网站空间，就是把一台运行在互联网上的服务器划分成多个虚拟的服务器，每一个虚拟主机都具有独立的域名和完整的Internet服务器(支持WWW、FTP、E-mail等)功能。在用户看来，这些不同的域名都会被解析到同一个IP上去，对应同一个服务器。

具体的实现就是使用反向代理，隔离不同的网络空间。

SSL在最早的版本对于虚拟主机没有足够的支持，因为在他们的握手中没有携带想要访问的域名的信息，这就导致服务器返回的证书可能是另外一个域名的证书，导致客户端在校验证书时发现证书无效，后来SSL也新增了对这个的支持。

### 什么是java虚拟机，我为什么要使用

是java字节码运行的平台，它是一种抽象化的计算机，通过在实际的计算机上仿真模拟各种计算机功能来实现的。Java虚拟机有自己完善的硬体架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。JVM屏蔽了与具体操作系统平台相关的信息，使得Java程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。

为什么要使用？因为字节码必须运行在java虚拟机上。难道还可以不用？

### 说一说java的运行内存区域

主要包括：堆、栈、本地方法栈、程序计数器、方法区、运行时常量池。部分java代码用到了JVM的本地内存。

### 讲一讲tcp协议的三次握手和四次挥手流程

三次握手：

1. 客户端向服务器发起连接请求SYN，并携带一个认证数字；
2. 服务器收到后，回复一个确认收到码ACK，并将客户端发过来的认证数字+1返回，然后再发送一个服务端的认证数字；
3. 客户端收到后，回复ACK，并返回服务器的认证数字+1。

这个用笑话讲就是：

1. Hi，我想跟你讲一个关于TCP的笑话。
2. 好的，我知道你想跟我讲一个关于TCP的笑话了，我准备接受你的笑话了。
3. 好的，我现在知道你已经准备好听我讲一个TCP的笑话了。

那么为什么要是三次呢？因为实际上是个双向认证的过程，客户端和服务器都需要确认对方是可以连接的。因此实际上是四次招呼，只不过服务器把确认收到以及向客户端打招呼放在一起了。

四次挥手，我们称对话双方为A和B

1. A向B发送FIN，表示我想发送的数据已经发送完了，即将关闭发送；
2. B向A发送ACK，表示知道你已经发送完了。
3. B向A发送FIN，表示我想发送的数据已经发送完了，即将关闭发送；
4. A向B发送ACK，表示知道你已经发送完了。

为什么这个需要4次，是因为TCP连接建立后可以双向发送数据，一方发送完毕后，另一方回复时自己并不一定没有数据需要发送了，因此不能把回复ACK和发送自己的FIN合并成一次传输，因此需要四次。

### 为什么tcp建立连接协议是三次握手，而关闭连接确是四次握手呢？为什么不能用两次握手进行连接？

之所以连接3次，挥手4次的原因上面已经讲了。但为什么不能用两次呢？

其实没有不能用，UDP一次也没有用，难道就不能发送消息了吗？还不是一样发。只是说TCP要求建立稳定的连接，而且连接建立后需要双向发送数据，因此服务端和客户端都确认一下能接收对方的消息是比较好的。不然可能会变成这样：

1. 我想给你讲个TCP的笑话。
2. 好的，你讲吧……waiting……怎么回事……喂喂，你还活着吗？

### 为什么TIME-WAIT状态需要等2MSL后才能回到CLOSED状态

+ 什么是TIMED_WAITING

  在“主动断开连接端”收到了“被动断开连接端”发来的LAST_ACK之后，会给“被动断开连接端”回复一个ACK确认消息。但这个时候为了确保“被动断开连接端”有足够的时间能够收到该消息，“主动断开连接端”不能马上关闭socket，需要等待一定的时间来确保“被动断开连接端”可以收到ACK确认消息。“主动断开连接端”在等待的这个时间段内的状态我们称之为TIME_WAIT状态。TIME_WAIT状态就是“主动断开的一方”在发送完最后一次ACK后进入的等待状态。

+ 什么是MSL

  Maximum Segment Lifetime，最长报文寿命。它是任何报文在网络上存在的最长的最长时间，超过这个时间报文将被丢弃。我们都知道IP头部中有个TTL字段，TTL是time to live的缩写，可译为“生存时间”，这个生存时间是由源主机设置设置初始值但不是但不是存在的具体时间，而是一个IP数据报可以经过的最大路由数，每经过一个路由器，它的值就减1，当此值为0则数据报被丢弃，同时发送ICMP报文通知源主机。虽然TTL实际上是跳数，但一跳和一跳之间的物理时间和网络环境有关系，RFC793中规定MSL为2分钟，但这完全是从工程上来考虑，对于现在的网络，MSL=2分钟可能太长了一些。因此TCP允许不同的实现可根据具体情况使用更小的MSL值。这个时间和系统的TCP实现有关，每个系统是不一样的。

主要是为了稳定和安全，究其原因，还是要面对网络的不可靠性，细细说来有这么两个原因：

1. 假设四次挥手的最后一步，A向B发送的ACK在网络传输中丢失了，然后B就会重发这个FIN，假如此时A连接已经直接关闭了，就会发生异常。但这不能解释这个问题：那就是假如有丢失的可能，那是不是还要考虑假如再丢失了一次咋办，而且为什么要等待2MSL？
2. 但更重要的原因是，假如双方发送的一个包迷失在网络空间，且已经重发并处理完了，之后双方的连接都已经关闭，这时候一个同样的四元组(source_ip,source_port,dest_ip,dest_port)立即又建立了连接，但是这个迷失的包又到了，此时其实接收端无法分辨这个包是上次连接的还是这次连接的，这就会引起混乱。所以需要维持一个状态，等待这个报文自然消亡在网络空间（TTL耗尽），而这个时间是一个经验时间，与具体实现有关。

### 描述一下Java异常层次结构

```
						|--->  Error
						|
Throwable-->|
						|										 |--->  CheckedException
						|--->  Exception --->|
						 										 |--->  RuntimeException
```

### 什么是检查异常，不受检查异常，运行时异常？并分别举例说明。

检查异常就是必须在代码里显式catch、或者在方法声明中声明抛出的异常，不然不能通过编译器检查。非检查异常则没有上述的限制。

比如IOException就是典型的检查异常，而NullPointer异常则是非检查异常。

运行时异常（RuntimeException）是所有不受检查异常的父类。

### Finally块一定会执行吗？

在程序运行正常，即：没有突然断电，JVM没有被意外杀死、提前终结的情况下，finally块一定会执行。但在以下情况下，finally块可能不会执行。

1. 在try中直接调用`System.exit()`退出JVM，因为JVM直接退出了，finally块不会执行。

   ```java
   public class Finally1 {
   
       public static void main(String[] args) {
           try {
               System.out.println("in try");
               System.exit(1);
           } finally {
               System.out.println("in finally");
           }
       }
   
   }
   ```

2. 守护线程中的finally块，在非守护线程全部退出时如果没有执行，就不会执行，因为此时JVM也退出了。

   ```java
   public class Finally2 {
   
       public static void main(String[] args) throws InterruptedException {
   
           Thread thread = new Thread(() -> {
               try {
                   System.out.println("in try");
                   TimeUnit.SECONDS.sleep(100);
               } catch (InterruptedException e) {
                   System.out.println("in catch");
               } finally {
                   System.out.println("in finally");
               }
           });
           thread.setDaemon(true);
           thread.start();
           TimeUnit.SECONDS.sleep(1);
   
       }
   
   }
   ```

### Try、catch、finally、return语句块的执行顺序

按try、catch、finally的顺序执行。如果没有异常不会进入catch，但不发生上面的情况，则一定会进入finally。

finally是在return语句执行之后，返回之前执行的（此时并没有返回运算后的值，而是先把要返回的值保存起来，不管finally中的代码怎么样，返回的值都不会改变，仍然是之前保存的值），所以函数返回值是在finally执行前就已经确定了；

finally中如果包含return，那么程序将在这里返回，而不是try或catch中的return返回，返回值就不是try或catch中保存的返回值了。但是在finally里包含return语句不是推荐做法，尽量别这么干。

### Java虚拟机中，数据类型可以分为哪几类

short，int，long，byte，char，float，double，boolean

在Java虚拟机中，false是由整数零来表示的，所有非零整数都表示true，涉及boolean值的操作则会使用int。另外，boolean数组是当做byte数组来访问的，但是在“堆”区，它也可以被表示为位域，由虚拟机的实现决定。

Java虚拟机的引用类型被统称为“引用（reference）”，有三种引用类型：类类型、接口类型、以及数组类型，它们的值都是对动态创建对象的引用。类类型的值是对类实例的引用；数组类型的值是对数组对象的引用，在Java虚拟机中，数组是个真正的对象；而接口类型的值，则是对实现了该接口的某个类实例的引用。还有一种特殊的引用值是null，它表示该引用变量没有引用任何对象。

### 怎么理解栈、堆？堆中存在什么？栈中存在什么？

栈是一个先进后出的数据结构，在操作系统的内存模型里，栈是一段专门开辟出来的空间，一般用于方法参数、返回位置、局部变量的存储，而因为这一块的使用方法刚好符合先进后出，所以被称为栈空间。而堆则用于保存进程在运行时创建出来的对象。

在java中，理论上所有新创建的对象都存在于堆上，但现在虚拟机的实现已经不太遵循这个理论模型，比如作为JVM优化措施之一的逃逸分析，分析一个对象的作用域不会超出当前方法，就有很大可能将这个对象分配在栈上，以避免给GC增加负担。另外，JIT优化过的代码是本地代码，会使用本地内存，对象也不会再堆里面分配，另外，原始类型不会在堆里面分配。

### 为什么要把堆和栈区分出来呢？栈中不是也可以存储数据吗？

栈更容易满足方法调用的需求，数据先进后出，调用多个方法逐个退出、递归调用的实现都非常方便，而且栈的实现使得这些数据的创建和销毁非常快，因为只需要移动栈指针就行了。在栈上定位数据，一般都是用与bps指针的相对位置。

但在栈上分配数据，就会导致一些长期使用的对象没法保存，因为移动栈指针之后当时分配的对象就可能被回收，而且跨方法的定位也会比较困难，因为bps指针是不断变化的。

### 在java中，什么是栈的起始点，同时也是程序的起始点？

一个含含糊糊的问题，他是想让我们回答main函数？

### 为什么不把基本类型放堆中呢？

这里应该是说单独作为一个变量的基本类型，而不是说某个类成员的基本类型。因为如果一个类的成员是基本类型，肯定会被放到堆里面去，所以这道题也不是很严谨。

那么为什么局部变量之类的放在栈上呢？我觉得有这么几个原因：

1. 基本类型并不是java中的一个对象，也就是说不继承自Object，因此缺少对象头等一些数据，放在堆里不好统一管理。
2. 基本类型本身很小，而且作为局部变量直接放在栈上可以减少寻址的开销（一般对象在栈上只是一个内存地址，其宽度和一个基本类型差不多，需要二次寻址）

### Java中的参数传递是传值呢?还是传引用？

什么是引用？引用是：一个对象的另一个名字。一旦初始化指向一个对象，就不能将其他对象重新赋值给该引用，这样引用和原对象的值都会被更改。比如下面这段CPP代码：

```cpp
#include<iostream>

using namespace std;

void dosth(int &c);

int main(){

    int a = 10;
    int &b = a;
    cout << a << "---" << b << endl;
    dosth(b);
    cout << a << "---" << b << endl;
    return 0;
}

void dosth(int &c){
    c = 100;
}
```

会得到下面的输出：

```shell
10---10
100---100
```

显然，引用具有一些特点，比如说：他一旦在初始化时指向一个对象，就不可能再引用其他对象，因为他就是初始化时引用的对象本身了，对该引用的一切改变会同时改变其引用的对象；引用不能指向null，而指针可以等等。

所以说，java中的传值其实并不是引用传值，而是值传递，传的是什么值呢？是变量的地址。上面的代码如果用java重写，大家都知道结果是什么，我就不写了。

### Java中有没有指针的概念？

这个问题比较诡异，你要说他没有，上面方法传值用的就是传对象地址，而对象地址实际上就是指针。但是你要说有这个概念，java里面的引用又没法定位真实的对象地址，更不可能像cpp里面一样直接给指针赋予一个int然后再强制转换去访问，所以这个问题不太清楚面试官想问什么。

### Java中，栈的大小通过什么参数来设置？

这个题出的很没水平，一个背诵题：

```
-XX:ThreadStackSize=256	（这个用法不标准，可以在不通知的情况下改变）
-Xss256k
```

但是可以借这道题来探索一下栈空间调优，可以参考这篇文章：[JDK 8: Thread Stack Size Tuning](http://xmlandmore.blogspot.com/2014/09/jdk-8-thread-stack-size-tuning.html)

其核心观点如下：

> In JDK 8, every time the JVM creates a thread, the OS allocates some native memory to hold that thread’s stack, committing more memory to the process until the thread exits. Thread stacks are fully allocated (i.e., *committed*, not just *reserved*) when they are created.
>
> This means that if your application spawns a lot of threads, this can consume a significant amount of memory which could otherwise be used by your application or OS (or it can eventually leads to *OutOfMemoryError*).
>
> - As a general rule, many applications can actually run with a 128 KB stack size in a 32-bit JVM, and a 256 KB stack size in a 64-bit JVM.
> - In a 64-bit JVM, there is usually no reason to set this value unless the machine is quite strained for physical memory and the smaller stack size will prevent applications from running out of native memory. 
> - On the other hand, using a smaller (e.g., 128 KB) stack size on a 32-bit JVM is often a good idea, as it frees up memory in the process size and allows the JVM to utilize a larger heap.

这篇文章的的大意是：在JDK1.8中，每一次JVM创建一个线程，系统就需要一些本地内存来容纳线程栈，为该进程提交更多的内存直到线程退出。线程栈内存是在线程创建后就立即分配的。所以如果你建立一大堆线程，就会消耗非常大的一块内存，而这些内存本来可以被你的进程使用或者被系统使用。

作为一个非强制性的建议，绝大部分应用都应该能在256kb栈（64位机器）或128k栈（32位机器）上运行，在64位机器上，一般没有理由去特别设置这个值，让JVM使用默认值就可以了，除非机器的物理内存确实非常吃紧，而且没有其他地方发生内存泄露等问题。

但是在32位机器上设置一个更小的栈空间（比如128kb）几乎总是一个好主意。

### 一个空Object对象的占多大空间？

这个题考查的是一个对象的内存布局。顺着这道题往下问，其实可以问对象初始化的过程。随便运行一个java进程，然后dump一下他的内存，查看dump文件中Object占据空间的大小，在64位机器上都是16byte。



## 不会

1. Redis讲一下，项目使用场景，以及对应的算法？

2. 分布式系统的全局id如何实现？用zookeeper如何实现的呢，机器号+时间戳即可？

3. 分布式锁的方案，redis和zookeeper那个好，如果是集群部署，高并发情况下哪个性能更好？

4. kafka了解么，了解哪些消息队列？

5. JVM内存模型，JVM加载原理，回收算法了解？

   JVM内存模型的意思并不是JVM运行时内存结构……而是指JMM，这方面还真不了解。
   
6. 说说java虚拟机的生命周期及体系结构

   不太搞得明白这个题问什么

7. 什么是分布式系统？

8. 分布式系统你会考虑哪些方面？

9. 什么是DoS、DDoS、DRDos攻击？如何防御？

## 题库

https://zhuanlan.zhihu.com/p/78673556

https://zhuanlan.zhihu.com/p/73202472

https://zhuanlan.zhihu.com/p/61216089

https://zhuanlan.zhihu.com/p/64147696

https://zhuanlan.zhihu.com/p/73903952